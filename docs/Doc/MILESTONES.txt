ATLAS — MILESTONES

Milestone 1 — MVP Backend (Postgres + Auth + RBAC + Core CRUD + TDD)
What needs to be done:
- Repo scaffolding for services/api
- FastAPI app with versioned routes (/api/v1)
- Postgres connection + SQLAlchemy models + Alembic migrations
- JWT Auth:
  - register, login, me
- RBAC model:
  - collections
  - memberships with role: owner/editor/viewer
  - enforcement rules:
    - only members can read
    - only owner/editor can create/update/delete items
    - only owner can manage members (recommended)
- Items + Tags:
  - create/update/delete item
  - list items per collection
  - tag association
- Pagination:
  - implement cursor pagination OR page/size
- Tests (TDD):
  - unit tests for service layer
  - integration tests for API endpoints and RBAC rules
Output of milestone:
- Running API locally with Postgres
- OpenAPI docs working
- Tests green

Prompt text for later (extensive):
"I have Milestone 1 completed and need help improving or extending it. Here is my current repo structure, database schema, and the endpoints. Please review and propose improvements for code organization, testing strategy, error handling, and RBAC enforcement. Provide concrete code-level suggestions and missing tests. Also suggest what should be refactored now vs later."

------------------------------------------------------------

Milestone 2 — Kafka Domain Events on Writes
What needs to be done:
- Add Kafka to local docker-compose
- Define event envelope (event_id, type, version, occurred_at, actor_user_id, entity, data, trace_id)
- Implement event publisher in API:
  - publish ItemCreated/ItemUpdated/ItemDeleted
  - publish CollectionCreated/Updated/Deleted
  - publish MembershipAdded/RoleChanged/Removed
- Add correlation/request ID propagation into events
- Tests:
  - verify publish is called on key write actions
  - validate envelope shape for a few events
Output of milestone:
- Events flowing into Kafka for core writes

Prompt text for later (extensive):
"I implemented Kafka domain events for Atlas. Please review my event envelope, topic strategy, and publishing logic. Suggest improvements for reliability (retries, batching), schema versioning, and how to test event publishing without flakiness. If my approach risks inconsistency between DB and Kafka, propose an incremental upgrade path (e.g., outbox)."

------------------------------------------------------------

Milestone 3 — Audit Stream (Kafka → Postgres Audit Trail)
What needs to be done:
- Create audit_events table in Postgres
- Build audit consumer service:
  - consumes domain events topic
  - writes immutable audit row
  - deduplicates by event_id (unique constraint)
  - handles retries/backoff
- Add audit query endpoints in API:
  - query by entity_type + entity_id
  - query by actor_user_id
  - query by collection_id + time range
- Tests:
  - consumer dedup test (same event twice)
  - audit query endpoints tests
Output of milestone:
- Audit trail automatically populated via events

Prompt text for later (extensive):
"My audit consumer is working and storing events. Please review my audit schema, indexing strategy, and query endpoints. Suggest improvements for performance, data redaction (if needed), and ensuring audit is tamper-resistant. Propose what audit fields are most valuable for real-world use and interviews."

------------------------------------------------------------

Milestone 4 — Search (Kafka → Indexer → Elasticsearch) + Search Endpoint
What needs to be done:
- Define Elasticsearch index mapping for Items
- Build indexer consumer service:
  - consumes item events
  - fetches item state from Postgres
  - upserts into Elasticsearch
  - deletes or soft-deletes on ItemDeleted
  - deduplicates by event_id
- Implement search endpoint in API:
  - GET /search/items?q=...&collection_id=...&tags=...&sort=...&order=...
  - enforce RBAC (only items from collections user can access)
- UX handling for eventual consistency (optional):
  - return indexing status in item responses
- Tests:
  - indexer unit tests for transformation of item -> ES doc
  - API tests for search filters and RBAC constraints
Output of milestone:
- Search works and scales, powered by Elasticsearch

Prompt text for later (extensive):
"I added Elasticsearch indexing and a search endpoint. Please review my index mapping, query design, and indexer logic. Suggest improvements for relevance ranking, pagination in search results, and how to securely enforce RBAC when search is in Elasticsearch. Propose optimizations and future enhancements (highlighting, fuzzy search, analyzers)."

------------------------------------------------------------

Milestone 5 — Background Jobs + Worker + Job Status API
What needs to be done:
- Create jobs table (type, status, payload, attempts, max_attempts, last_error)
- Implement worker service:
  - polls for QUEUED jobs
  - locks a job row safely
  - executes handler with timeout + retries
  - updates job status and related item metadata
- Implement API endpoints:
  - POST /jobs (create job)
  - GET /jobs/{id} (status)
  - GET /jobs?status=...
- Job types (initial):
  - ENRICH_URL: fetch title/description from item.source_url and store in item.metadata_json
  - REINDEX_ITEM: trigger reindex (optional)
- Tests:
  - job lifecycle tests (queued -> running -> success/fail)
  - idempotent retries
Output of milestone:
- Async processing pipeline with visible job status

Prompt text for later (extensive):
"My worker and job system is in place. Please review concurrency safety, job locking strategy, retry logic, and idempotency guarantees. Suggest improvements for scaling workers, preventing duplicate work, and separating job handlers cleanly. Recommend what metrics/logs I should add."

------------------------------------------------------------

Milestone 6 — Cloud-Native Readiness (Local)
What needs to be done:
- Config via env vars (12-factor style)
- /health and /ready endpoints
- Structured logs with request_id/trace_id
- Metrics endpoint (Prometheus-ready)
- Basic rate limiting (optional)
- Runbook notes: how to debug locally
Output of milestone:
- Services behave like production services

Prompt text for later (extensive):
"I want to prepare Atlas for cloud-native deployment. Please review my config approach, health/readiness checks, logging, and metrics. Suggest what should be added for production readiness and what can be deferred. Provide a checklist aligned with best practices."

------------------------------------------------------------

Milestone 7 — React Frontend
What needs to be done:
- UI: login/register, collections dashboard, items list/editor, search page, job status page, audit viewer
- API integration with auth token storage
- Error states and loading states
Output of milestone:
- Full-stack product demo

Prompt text for later (extensive):
"I built the React frontend for Atlas. Please review the UI flows, API integration, state management approach, and security practices for storing tokens. Suggest improvements for UX, performance, and accessibility."

------------------------------------------------------------

Milestone 8 — Local Kubernetes (kind/minikube)
What needs to be done:
- K8s manifests or Helm: Deployments, Services, Ingress, ConfigMaps/Secrets
- Resource requests/limits + probes
- Local k8s runs end-to-end
Output of milestone:
- Kubernetes deployment skills proven locally

Prompt text for later (extensive):
"I deployed Atlas to local Kubernetes. Please review my manifests/Helm charts for best practices: probes, resources, secrets, ingress, and scaling. Suggest how to structure overlays and how to test deployments."

------------------------------------------------------------

Milestone 9 — GCP Deployment + DevSecOps Pipeline (GKE Autopilot + Cloud SQL)
What needs to be done:
- Provision GCP: Artifact Registry, GKE Autopilot, Cloud SQL
- CI/CD pipeline:
  - tests, lint, typecheck
  - dependency scanning + secrets scanning
  - container scanning
  - deploy to GKE
- Observability using GCP logging/monitoring dashboards
Output of milestone:
- Live deployed project + professional pipeline

Prompt text for later (extensive):
"I deployed Atlas to GCP (GKE Autopilot + Cloud SQL). Please review my CI/CD pipeline, security scanning setup, deployment strategy, secrets management, and observability. Suggest improvements for GitOps, supply chain security (SBOM/signing), and cost controls."
